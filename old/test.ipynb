{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "\n",
    "from PAMI.highUtilityPattern.parallel import abstract as _ab\n",
    "\n",
    "\n",
    "def binarySearch(arr, x):\n",
    "    l = 0\n",
    "    r = len(arr) - 1\n",
    "    while l <= r:\n",
    "        mid = l + (r - l) // 2\n",
    "        if arr[mid] == x:\n",
    "            return mid\n",
    "        elif arr[mid] < x:\n",
    "            l = mid + 1\n",
    "        else:\n",
    "            r = mid - 1\n",
    "    return -1\n",
    "\n",
    "class efimParallel(_ab._utilityPatterns):\n",
    "\n",
    "    def __init__(self, iFile, minUtil, sep=\"\\t\", threads=1):\n",
    "        super().__init__(iFile, minUtil, sep)\n",
    "        self.inputFile = iFile\n",
    "        self.minUtil = minUtil\n",
    "        self.sep = sep\n",
    "        self.Patterns = {}\n",
    "        self.rename = {}\n",
    "        self.threads = threads\n",
    "\n",
    "    # Read input file\n",
    "    def _read_file(self):\n",
    "\n",
    "        file_data = []\n",
    "        twu = {}\n",
    "\n",
    "        with open(self.inputFile, 'r') as f:\n",
    "\n",
    "            for line in f:\n",
    "                line = line.strip().split(\":\")\n",
    "                \n",
    "                # Parse and process the line\n",
    "                line = [x.split(self.sep) for x in line]\n",
    "                weight = int(line[1][0])\n",
    "\n",
    "                # Update file data with the parsed items\n",
    "                file_data.append([line[0], [int(x) for x in line[2]]])\n",
    "\n",
    "                for k in line[0]:\n",
    "                    if k not in twu:\n",
    "                        twu[k] = 0\n",
    "                    twu[k] += weight\n",
    "\n",
    "        # Filter TWU dictionary based on minUtil (minimum utility threshold)\n",
    "        twu = {k: v for k, v in twu.items() if v >= self.minUtil}\n",
    "\n",
    "        # Sort TWU items by utility\n",
    "        twu = {k: v for k, v in sorted(twu.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        strToInt = {}\n",
    "        t = len(twu)\n",
    "        for k in twu.keys():\n",
    "            strToInt[k] = t\n",
    "            self.rename[t] = k\n",
    "            t -= 1\n",
    "\n",
    "        # Filter and sort transactions\n",
    "        subtree = {}\n",
    "        filtered_transactions = {}\n",
    "        for col in file_data:\n",
    "            zipped = zip(col[0], col[1])\n",
    "            transaction = [(strToInt[x], y) for x, y in zipped if x in strToInt]\n",
    "            if len(transaction) > 0:\n",
    "                transaction = sorted(transaction, key=lambda x: x[0])\n",
    "                \n",
    "                key = [x[0] for x in transaction]\n",
    "                val = [x[1] for x in transaction]\n",
    "                \n",
    "                fs = frozenset(key)\n",
    "                \n",
    "                if fs not in filtered_transactions:\n",
    "                    filtered_transactions[fs] = [key, val, 0]\n",
    "                else:\n",
    "                    for i in range(len(val)):\n",
    "                        filtered_transactions[fs][1][i] += val[i]\n",
    "\n",
    "                subUtil = sum([x[1] for x in transaction])\n",
    "                temp = 0\n",
    "\n",
    "                for i in range(len(transaction)):\n",
    "                    item = key[i]\n",
    "                    if item not in subtree:\n",
    "                        subtree[item] = subUtil - temp\n",
    "                    else:\n",
    "                        subtree[item] += subUtil - temp\n",
    "                    temp += val[i]\n",
    "\n",
    "        primary = [key for key in subtree.keys() if subtree[key] >= self.minUtil]\n",
    "        \n",
    "        return filtered_transactions, primary\n",
    "\n",
    "    def _search(self, prefix, fileData, primary):\n",
    "        \n",
    "        for item in primary:\n",
    "            n_fd = {}\n",
    "            local_util = {}\n",
    "            \n",
    "            for key, value in fileData.items():\n",
    "                if item in key:\n",
    "                    index = binarySearch(value[0], item) + 1\n",
    "                    \n",
    "                    fs = frozenset(value[0][index:])\n",
    "                    \n",
    "                    if fs not in n_fd:\n",
    "                        n_fd[fs] = [value[0][index:], value[1][index:], value[2] + value[1][index - 1]]\n",
    "                    else:\n",
    "                        for i in range(len(value[1][index:])):\n",
    "                            n_fd[fs][1][i] += value[1][index + i]\n",
    "                        n_fd[fs][2] += value[2] + value[1][index - 1]\n",
    "                    \n",
    "                    tran_total = sum(value[1][index:]) + value[2] + value[1][index - 1]\n",
    "                    \n",
    "                    for value in value[0][index:]:\n",
    "                        if value not in local_util:\n",
    "                            local_util[value] = 0\n",
    "                        local_util[value] += tran_total\n",
    "            \n",
    "            total = sum([x[2] for x in n_fd.values()])\n",
    "            if total >= self.minUtil:\n",
    "                pattern = \"\\t\".join([self.rename[x] for x in prefix + [item]])\n",
    "                self.Patterns[pattern] = total\n",
    "                \n",
    "            n_fd2 = {}\n",
    "            subtree_util = {}\n",
    "            \n",
    "            for key, value in n_fd.items():                \n",
    "                keys = []\n",
    "                vals = []\n",
    "                # print(\"Value:\", value)\n",
    "                for i in range(len(value[0])):\n",
    "                    if local_util[value[0][i]] >= self.minUtil:\n",
    "                        keys.append(value[0][i])\n",
    "                        vals.append(value[1][i])\n",
    "                \n",
    "                if len(keys) == 0:\n",
    "                    continue\n",
    "                        \n",
    "                total = sum(vals) + value[2]\n",
    "                temp = 0\n",
    "                for i in range(len(keys)):\n",
    "                    if keys[i] not in subtree_util:\n",
    "                        subtree_util[keys[i]] = 0\n",
    "                    subtree_util[keys[i]] += total - temp\n",
    "                    temp += vals[i]\n",
    "                \n",
    "                fs = frozenset(keys)\n",
    "                if fs not in n_fd2:\n",
    "                    n_fd2[fs] = [keys, vals, value[2]]\n",
    "                else:\n",
    "                    for i in range(len(vals)):\n",
    "                        # n_fd2[fs][2][i] += vals[i]\n",
    "                        n_fd2[fs][1][i] += vals[i]\n",
    "                    n_fd2[fs][2] += value[2]\n",
    "                            \n",
    "            \n",
    "            primary = [key for key in subtree_util.keys() if subtree_util[key] >= self.minUtil]\n",
    "                            \n",
    "            if len(primary) > 0:\n",
    "                self._search(prefix + [item], n_fd2, primary)\n",
    "\n",
    "    def startMine(self):\n",
    "        self.mine()\n",
    "\n",
    "    def mine(self):\n",
    "        ps = psutil.Process(os.getpid())\n",
    "\n",
    "        self.start = time.time()\n",
    "\n",
    "        fileData, primary = self._read_file()\n",
    "\n",
    "        self._search([], fileData, primary)\n",
    "        \n",
    "        self.memoryRSS = ps.memory_info().rss\n",
    "        self.memoryUSS = ps.memory_full_info().uss\n",
    "\n",
    "        end = time.time()\n",
    "        self.runtime = end - self.start\n",
    "\n",
    "    def save(self, outFile):\n",
    "        self.oFile = outFile\n",
    "        writer = open(self.oFile, 'w+')\n",
    "        for x, y in self._finalPatterns.items():\n",
    "            patternsAndSupport = x.strip() + \":\" + str(y)\n",
    "            writer.write(\"%s \\n\" % patternsAndSupport)\n",
    "    \n",
    "    def getPatternsAsDataFrame(self):\n",
    "        dataFrame = {}\n",
    "        data = []\n",
    "        for a, b in self._finalPatterns.items():\n",
    "            data.append([a.replace('\\t', ' '), b])\n",
    "            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Utility'])\n",
    "\n",
    "        return dataFrame\n",
    "\n",
    "    def getPatterns(self):\n",
    "        return self.Patterns\n",
    "\n",
    "    def getRuntime(self):\n",
    "        return self.runtime\n",
    "\n",
    "    def getMemoryRSS(self):\n",
    "        return self.memoryRSS\n",
    "\n",
    "    def getMemoryUSS(self):\n",
    "        return self.memoryUSS\n",
    "\n",
    "\n",
    "    def printResults(self):\n",
    "        print(\"Total number of High Utility Patterns:\", len(self.getPatterns()))\n",
    "        print(\"Total Memory in USS:\", self.getMemoryUSS())\n",
    "        print(\"Total Memory in RSS\", self.getMemoryRSS())\n",
    "        print(\"Total ExecutionTime in seconds:\", self.getRuntime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# obj = efimParallel(\"/home/tarun/cuEFIM/datasets/accidents_utility_spmf.txt\", 15000000, \" \")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m obj \u001b[38;5;241m=\u001b[39m efimParallel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m obj\u001b[38;5;241m.\u001b[39mprintResults()\n",
      "Cell \u001b[0;32mIn[1], line 181\u001b[0m, in \u001b[0;36mefimParallel.mine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m ps \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mProcess(os\u001b[38;5;241m.\u001b[39mgetpid())\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 181\u001b[0m fileData, primary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search([], fileData, primary)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoryRSS \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mefimParallel._read_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m file_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     37\u001b[0m twu \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     42\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
     ]
    }
   ],
   "source": [
    "# obj = efimParallel(\"/home/tarun/cuEFIM/datasets/accidents_utility_spmf.txt\", 15000000, \" \")\n",
    "obj = efimParallel(\"/home/tarun/testing/test.txt\", 40, \" \")\n",
    "obj.mine()\n",
    "obj.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t5\t3 : 31\n",
      "4\t3 : 34\n",
      "4\t2 : 44\n",
      "4\t2\t5 : 53\n",
      "4\t2\t5\t3 : 60\n",
      "4\t2\t3 : 51\n",
      "4\t5 : 33\n",
      "4\t5\t3 : 40\n",
      "2\t5 : 36\n",
      "2\t5\t3 : 45\n",
      "2\t3 : 33\n",
      "5\t3 : 33\n",
      "6\t1\t4\t2\t5\t3 : 30\n"
     ]
    }
   ],
   "source": [
    "for k,v in obj.getPatterns().items():\n",
    "    print(k,\":\", v)\n",
    "pami = [v for k,v in obj.getPatterns().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = [31,33,36,45,44,51,53,60,34,33,40,33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 31, 33, 33, 33, 34, 36, 40, 44, 45, 51, 53, 60]\n",
      "[31, 33, 33, 33, 34, 36, 40, 44, 45, 51, 53, 60]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(pami))\n",
    "print(sorted(my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6\t1\t4\t2\t5\t3 : 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mmap\n",
    "import time\n",
    "import psutil\n",
    "from joblib import Parallel, delayed\n",
    "from deprecated import deprecated\n",
    "\n",
    "\n",
    "from PAMI.highUtilityPattern.parallel import abstract as _ab\n",
    "\n",
    "class efimParallel(_ab._utilityPatterns):\n",
    "    \"\"\"\n",
    "    :Description:   EFIM is one of the fastest algorithm to mine High Utility ItemSets from transactional databases.\n",
    "    \n",
    "    :Reference:     Zida, S., Fournier-Viger, P., Lin, J.CW. et al. EFIM: a fast and memory efficient algorithm for\n",
    "                     high-utility itemset mining. Knowl Inf Syst 51, 595â€“625 (2017). https://doi.org/10.1007/s10115-016-0986-0\n",
    "\n",
    "    :param  iFile: str :\n",
    "                   Name of the Input file to mine complete set of High Utility patterns\n",
    "    :param  oFile: str :\n",
    "                   Name of the output file to store complete set of High Utility patterns\n",
    "    :param minUtil: int :\n",
    "                   The user given minUtil value.\n",
    "    :param maxMemory: int\n",
    "                   Maximum memory used by this program for running\n",
    "    :param  sep: str :\n",
    "                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.\n",
    "\n",
    "\n",
    "    :Attributes:\n",
    "\n",
    "        inputFile (str):\n",
    "            The input file path.\n",
    "        minUtil (int):\n",
    "            The minimum utility threshold.\n",
    "        sep (str):\n",
    "            The separator used in the input file.\n",
    "        threads (int):\n",
    "            The number of threads to use.\n",
    "        Patterns (dict):\n",
    "            A dictionary containing the discovered patterns.\n",
    "        rename (dict):\n",
    "            A dictionary containing the mapping between the item IDs and their names.\n",
    "        runtime (float):\n",
    "            The runtime of the algorithm in seconds.\n",
    "        memoryRSS (int):\n",
    "            The Resident Set Size (RSS) memory usage of the algorithm in bytes.\n",
    "        memoryUSS (int):\n",
    "            The Unique Set Size (USS) memory usage of the algorithm in bytes.\n",
    "\n",
    "    :Methods:\n",
    "\n",
    "        read_file():\n",
    "            Read the input file and return the filtered transactions, primary items, and secondary items.\n",
    "        binarySearch(arr, item):\n",
    "            Perform a binary search on the given array to find the given item.\n",
    "        project(beta, file_data, secondary):\n",
    "            Project the given beta itemset on the given database.\n",
    "        search(collections):\n",
    "            Search for high utility itemsets in the given collections.\n",
    "        mine():\n",
    "            Start the EFIM algorithm.\n",
    "        savePatterns(outputFile):\n",
    "            Save the patterns discovered by the algorithm to an output file.\n",
    "        getPatterns():\n",
    "            Get the patterns discovered by the algorithm.\n",
    "        getRuntime():\n",
    "            Get the runtime of the algorithm.\n",
    "        getMemoryRSS():\n",
    "            Get the Resident Set Size (RSS) memory usage of the algorithm.\n",
    "        getMemoryUSS():\n",
    "            Get the Unique Set Size (USS) memory usage of the algorithm.\n",
    "        printResults():\n",
    "            Print the results of the algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iFile, minUtil, sep=\"\\t\", threads=1):\n",
    "        super().__init__(iFile, minUtil, sep)\n",
    "        self.inputFile = iFile\n",
    "        self.minUtil = minUtil\n",
    "        self.sep = sep\n",
    "        self.Patterns = {}\n",
    "        self.rename = {}\n",
    "        self.threads = threads\n",
    "\n",
    "    # Read input file\n",
    "    def _read_file(self):\n",
    "        \"\"\"\n",
    "        Read the input file and return the filtered transactions, primary items, and secondary items.\n",
    "\n",
    "        :return:\n",
    "\n",
    "            filtered_transactions (dict): A dictionary containing the filtered transactions.\n",
    "            primary (set): A set containing the primary items.\n",
    "            secondary (set): A set containing the secondary items.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        file_data = []\n",
    "        twu = {}\n",
    "\n",
    "        with open(self.inputFile, 'r') as f:\n",
    "            fd = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "\n",
    "            for line in iter(fd.readline, b\"\"):\n",
    "                line = line.decode('utf-8').strip().split(\":\")\n",
    "                \n",
    "                # Parse and process the line\n",
    "                line = [x.split(self.sep) for x in line]\n",
    "                weight = int(line[1][0])\n",
    "\n",
    "                # Update file data with the parsed items\n",
    "                file_data.append([line[0], [int(x) for x in line[2]]])\n",
    "\n",
    "                for k in line[0]:\n",
    "                    if k not in twu:\n",
    "                        twu[k] = weight\n",
    "                    else:\n",
    "                        twu[k] += weight\n",
    "\n",
    "        # Filter TWU dictionary based on minUtil (minimum utility threshold)\n",
    "        twu = {k: v for k, v in twu.items() if v >= self.minUtil}\n",
    "\n",
    "        # Sort TWU items by utility\n",
    "        twu = {k: v for k, v in sorted(twu.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        strToInt = {}\n",
    "        t = len(twu)\n",
    "        for k in twu.keys():\n",
    "            strToInt[k] = t\n",
    "            self.rename[t] = k\n",
    "            t -= 1\n",
    "\n",
    "        secondary = set(self.rename.keys())\n",
    "\n",
    "        # Filter and sort transactions\n",
    "        subtree = {}\n",
    "        filtered_transactions = {}\n",
    "        for col in file_data:\n",
    "            zipped = zip(col[0], col[1])\n",
    "            transaction = [(strToInt[x], y) for x, y in zipped if x in strToInt]\n",
    "            transaction = sorted(transaction, key=lambda x: x[0])\n",
    "            if len(transaction) > 0:\n",
    "                val = [x[1] for x in transaction]\n",
    "                key = [x[0] for x in transaction]\n",
    "                \n",
    "                fs = frozenset(key)\n",
    "\n",
    "                if fs not in filtered_transactions:\n",
    "                    filtered_transactions[fs] = [key, val, 0]\n",
    "                else:\n",
    "                    filtered_transactions[fs][1] = [x + y for x, y in zip(filtered_transactions[fs][1], val)]\n",
    "\n",
    "                subUtil = sum([x[1] for x in transaction])\n",
    "                temp = 0\n",
    "\n",
    "                for i in range(len(transaction)):\n",
    "                    item = key[i]\n",
    "                    if item not in subtree:\n",
    "                        subtree[item] = subUtil - temp\n",
    "                    else:\n",
    "                        subtree[item] += subUtil - temp\n",
    "                    temp += val[i]\n",
    "\n",
    "        primary = [key for key in subtree.keys() if subtree[key] >= self.minUtil]\n",
    "\n",
    "        return filtered_transactions, primary, secondary\n",
    "    \n",
    "\n",
    "    def _binarySearch(self, arr, item):\n",
    "        \"\"\"\n",
    "        Do a binary search on the given array to find the given item.\n",
    "\n",
    "        :param arr: The array to search in\n",
    "\n",
    "        :type arr: list\n",
    "\n",
    "        :param item: The item to search for\n",
    "\n",
    "        :type item: int\n",
    "\n",
    "        :return:\n",
    "\n",
    "            mid (int):\n",
    "                The index of the item if found, -1 otherwise.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        low = 0\n",
    "        high = len(arr) - 1\n",
    "        mid = 0\n",
    "\n",
    "        while low <= high:\n",
    "            mid = (high + low) // 2\n",
    "            if arr[mid] < item:\n",
    "                low = mid + 1\n",
    "            elif arr[mid] > item:\n",
    "                high = mid - 1\n",
    "            else:\n",
    "                return mid\n",
    "\n",
    "        return -1\n",
    "\n",
    "    def _project(self, beta, file_data, secondary):\n",
    "        \"\"\"\n",
    "        Project the given beta itemset on the given database.\n",
    "\n",
    "        :param beta: The beta itemset to project\n",
    "\n",
    "        :type beta: list\n",
    "\n",
    "        :param file_data: The database to project on\n",
    "\n",
    "        :type file_data: dict\n",
    "\n",
    "        :param secondary: The set of secondary items\n",
    "\n",
    "        :type secondary: set\n",
    "\n",
    "        :return:\n",
    "\n",
    "            projected_db (dict): The projected database.\n",
    "            local_utils (dict): The local utilities of the projected database.\n",
    "            subtree_utils (dict): The subtree utilities of the projected database.\n",
    "            utility (int): The utility of the projected database.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        projected_db = {}\n",
    "        local_utils = {}\n",
    "        subtree_utils = {}\n",
    "        utility = 0     \n",
    "\n",
    "        added = set()\n",
    "\n",
    "        item = beta[-1]\n",
    "\n",
    "        temp = [v for k, v in file_data.items() if item in k]\n",
    "        start = time.time()\n",
    "\n",
    "        for v in temp:\n",
    "            index = self._binarySearch(v[0], item)\n",
    "\n",
    "            curr = v[1][index] + v[2]\n",
    "            utility += curr\n",
    "\n",
    "            newKey = []\n",
    "            newVal = []\n",
    "\n",
    "            for i in range(index+1, len(v[0])):\n",
    "                if v[0][i] in secondary:\n",
    "                    newKey.append(v[0][i])\n",
    "                    newVal.append(v[1][i])\n",
    "\n",
    "            if len(newKey) == 0:\n",
    "                continue\n",
    "\n",
    "            s = sum(newVal)\n",
    "            temp = 0\n",
    "\n",
    "            for i in range(len(newKey)):\n",
    "                if newKey[i] in added:\n",
    "                    local_utils[newKey[i]] += s + curr\n",
    "                    subtree_utils[newKey[i]] += s + curr - temp\n",
    "                else:\n",
    "                    local_utils[newKey[i]] = s + curr\n",
    "                    subtree_utils[newKey[i]] = s + curr - temp\n",
    "                    added.add(newKey[i])\n",
    "                \n",
    "                temp += newVal[i]\n",
    "            \n",
    "            fs = frozenset(newKey)\n",
    "\n",
    "            if fs not in projected_db:\n",
    "                projected_db[fs] = [newKey, newVal, curr]\n",
    "            else:\n",
    "                projected_db[fs][1] = [x + y for x, y in zip(projected_db[fs][1], newVal)]\n",
    "                projected_db[fs][2] += curr\n",
    "\n",
    "        nprimary = [key for key in subtree_utils.keys() if subtree_utils[key] >= self.minUtil]\n",
    "        print(subtree_utils)\n",
    "        nsecondary = set([key for key in local_utils.keys() if local_utils[key] >= self.minUtil])\n",
    "        \n",
    "        # print(subtree_utils)\n",
    "        # print(local_utils)\n",
    "\n",
    "        return beta, projected_db, nsecondary, nprimary, utility\n",
    "    \n",
    "\n",
    "    def _search(self, collections):\n",
    "\n",
    "        \"\"\"\n",
    "        Search for frequent patterns in the given collections.\n",
    "\n",
    "        :param collections: The collections to search in\n",
    "\n",
    "        :type collections: list\n",
    "        \"\"\"\n",
    "\n",
    "        if (self.threads > 1):\n",
    "            with Parallel(n_jobs=self.threads) as parallel:\n",
    "                while len(collections) > 0:\n",
    "                    new_collections = []\n",
    "\n",
    "                    # print(\"Num of tasks:\", sum(len(collections[i][2]) for i in range(len(collections))))\n",
    "                    results = parallel(delayed(self._project)(collections[i][0] + [collections[i][2][j]], collections[i][1], collections[i][3]) for i in range(len(collections)) for j in range(len(collections[i][2])))\n",
    "\n",
    "                    for i in range(len(results)):\n",
    "                        beta, projected_db, secondary, primary, utility = results[i]\n",
    "                        if utility >= self.minUtil:\n",
    "                            pattern = \"\\t\".join([self.rename[x] for x in beta])\n",
    "                            # self.Patterns[tuple(beta)] = utility\n",
    "                            self.Patterns[pattern] = utility\n",
    "                        if len(primary) > 0:\n",
    "                            new_collections.append([beta, projected_db, primary, secondary])\n",
    "                    \n",
    "                    collections = new_collections\n",
    "\n",
    "        else:\n",
    "            while len(collections) > 0:\n",
    "                new_collections = []\n",
    "                for i in range(len(collections)):\n",
    "                    for j in range(len(collections[i][2])):\n",
    "                        beta, projected_db, secondary, primary, utility = self._project(collections[i][0] + [collections[i][2][j]], collections[i][1], collections[i][3])\n",
    "                        print(beta, utility)\n",
    "                        print(projected_db)\n",
    "                        # print(secondary)\n",
    "                        print(primary)\n",
    "                        print()\n",
    "                        if utility >= self.minUtil:\n",
    "                            # pattern = \"\\t\".join([self.rename[x] for x in beta])\n",
    "                            pattern = \"\\t\".join([str(x) for x in beta])\n",
    "                            # self.Patterns[tuple(beta)] = utility\n",
    "                            self.Patterns[pattern] = utility\n",
    "                        if len(primary) > 0:\n",
    "                            new_collections.append([beta, projected_db, primary, secondary])\n",
    "\n",
    "                collections = new_collections\n",
    "\n",
    "\n",
    "    @deprecated(\"It is recommended to use 'mine()' instead of 'mine()' for mining process. Starting from January 2025, 'mine()' will be completely terminated.\")\n",
    "    def startMine(self):\n",
    "        \"\"\"\n",
    "        Start the EFIM algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        self.mine()\n",
    "\n",
    "    def mine(self):\n",
    "        \"\"\"\n",
    "        Start the EFIM algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        ps = psutil.Process(os.getpid())\n",
    "\n",
    "        self.start = time.time()\n",
    "\n",
    "        fileData, primary, secondary = self._read_file()\n",
    "\n",
    "        collection = [[[], fileData, primary, secondary]]\n",
    "\n",
    "        self._search(collection)\n",
    "\n",
    "        self.memoryRSS = ps.memory_info().rss\n",
    "        self.memoryUSS = ps.memory_full_info().uss\n",
    "\n",
    "        end = time.time()\n",
    "        self.runtime = end - self.start\n",
    "\n",
    "    def save(self, outFile):\n",
    "        \"\"\"\n",
    "        Complete set of frequent patterns will be loaded in to an output file\n",
    "        :param outFile: name of the output file\n",
    "        :type outFile: csv file\n",
    "        \"\"\"\n",
    "        self.oFile = outFile\n",
    "        writer = open(self.oFile, 'w+')\n",
    "        for x, y in self._finalPatterns.items():\n",
    "            patternsAndSupport = x.strip() + \":\" + str(y)\n",
    "            writer.write(\"%s \\n\" % patternsAndSupport)\n",
    "    \n",
    "    def getPatternsAsDataFrame(self):\n",
    "        \"\"\"\n",
    "        Storing final patterns in a dataframe\n",
    "        :return: returning patterns in a dataframe\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        dataFrame = {}\n",
    "        data = []\n",
    "        for a, b in self._finalPatterns.items():\n",
    "            data.append([a.replace('\\t', ' '), b])\n",
    "            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Utility'])\n",
    "\n",
    "        return dataFrame\n",
    "\n",
    "    def getPatterns(self):\n",
    "        \"\"\"\n",
    "        Get the patterns discovered by the algorithm.\n",
    "\n",
    "        :return: A dictionary containing the discovered patterns.\n",
    "\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        return self.Patterns\n",
    "\n",
    "    def getRuntime(self):\n",
    "        \"\"\"\n",
    "        Get the runtime of the algorithm.\n",
    "\n",
    "        :return: The runtime in seconds.\n",
    "\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        return self.runtime\n",
    "\n",
    "    def getMemoryRSS(self):\n",
    "        \"\"\"\n",
    "        Get the Resident Set Size (RSS) memory usage of the algorithm.\n",
    "\n",
    "        :return: The RSS memory usage in bytes.\n",
    "\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.memoryRSS\n",
    "\n",
    "    def getMemoryUSS(self):\n",
    "        \"\"\"\n",
    "        Get the Unique Set Size (USS) memory usage of the algorithm.\n",
    "\n",
    "        :return: The USS memory usage in bytes.\n",
    "\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.memoryUSS\n",
    "\n",
    "\n",
    "    def printResults(self):\n",
    "        \"\"\"\n",
    "        This function is used to print the results\n",
    "        \"\"\"\n",
    "        print(\"Total number of High Utility Patterns:\", len(self.getPatterns()))\n",
    "        print(\"Total Memory in USS:\", self.getMemoryUSS())\n",
    "        print(\"Total Memory in RSS\", self.getMemoryRSS())\n",
    "        print(\"Total ExecutionTime in seconds:\", self.getRuntime())\n",
    "\n",
    "# obj = efimParallel(\"/home/tarun/cuEFIM/datasets/accidents_utility_spmf.txt\", 15000000, \" \")\n",
    "# obj.mine()\n",
    "# obj.printResults()\n",
    "\n",
    "# for k,v in obj.getPatterns().items():\n",
    "#     print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 33, 5: 28, 4: 31, 3: 13}\n",
      "[1] 20\n",
      "{frozenset({2, 5}): [[2, 5], [2, 1], 5], frozenset({4, 5}): [[4, 5], [6, 6], 10], frozenset({2, 3, 4, 5}): [[2, 3, 4, 5], [12, 4, 3, 1], 5]}\n",
      "[]\n",
      "\n",
      "{5: 34, 3: 60, 4: 40}\n",
      "[2] 26\n",
      "{frozenset({5}): [[5], [1], 2], frozenset({3, 4, 5}): [[3, 4, 5], [20, 9, 7], 24]}\n",
      "[3, 4]\n",
      "\n",
      "{4: 45, 5: 33}\n",
      "[3] 24\n",
      "{frozenset({4, 5}): [[4, 5], [12, 9], 24]}\n",
      "[4]\n",
      "\n",
      "{4: 60, 5: 51}\n",
      "[2, 3] 44\n",
      "{frozenset({4, 5}): [[4, 5], [9, 7], 44]}\n",
      "[4, 5]\n",
      "\n",
      "{5: 40}\n",
      "[2, 4] 33\n",
      "{frozenset({5}): [[5], [7], 33]}\n",
      "[5]\n",
      "\n",
      "{5: 45}\n",
      "[3, 4] 36\n",
      "{frozenset({5}): [[5], [9], 36]}\n",
      "[5]\n",
      "\n",
      "{5: 60}\n",
      "[2, 3, 4] 53\n",
      "{frozenset({5}): [[5], [7], 53]}\n",
      "[5]\n",
      "\n",
      "{}\n",
      "[2, 3, 5] 51\n",
      "{}\n",
      "[]\n",
      "\n",
      "{}\n",
      "[2, 4, 5] 40\n",
      "{}\n",
      "[]\n",
      "\n",
      "{}\n",
      "[3, 4, 5] 45\n",
      "{}\n",
      "[]\n",
      "\n",
      "{}\n",
      "[2, 3, 4, 5] 60\n",
      "{}\n",
      "[]\n",
      "\n",
      "Total number of High Utility Patterns: 6\n",
      "Total Memory in USS: 118292480\n",
      "Total Memory in RSS 120049664\n",
      "Total ExecutionTime in seconds: 0.00407862663269043\n"
     ]
    }
   ],
   "source": [
    "obj = efimParallel(\"test.txt\", 40, \" \")\n",
    "obj.mine()\n",
    "obj.printResults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t3 44\n",
      "2\t3\t4 53\n",
      "2\t3\t5 51\n",
      "2\t4\t5 40\n",
      "3\t4\t5 45\n",
      "2\t3\t4\t5 60\n"
     ]
    }
   ],
   "source": [
    "for k,v in obj.getPatterns().items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
